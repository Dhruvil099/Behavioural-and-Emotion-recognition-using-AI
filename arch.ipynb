{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('model_CNN.h5')\n",
    "model2 = load_model('LSTMcombined_2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 23, 23, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 10, 10, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,144,325\n",
      "Trainable params: 1,144,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,127\n",
      "Trainable params: 77,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "洧냢 洧멇롐뀛롐뛿롐뢣롐뙗롐 洧녶洧녭 900 洧녰洧노洧뉧롐뛿롐 洧녰洧 洧녭洧녶洧녹洧녵洧녬 洧노洧녶 h洧녩洧녺洧 洧녩 洧녴洧뉧롐뀛롐 洧녶洧녭 3.47 洧녫洧녴. 洧냤洧녩洧녵 洧녰洧노 洧녪洧 洧洧뉧롐뀛롐멇롐럻롐洧녩洧녪洧녳洧녽 洧洧뉧롐덣롐뀛롐洧녬洧뉧롐 洧녩洧 洧녩 洧멇롐뒳롐뛿롐뢣롐뙗롐 洧멇롐뀛롐뛿롐뢣롐뙗롐 洧녭洧洧녶洧녴 洧녩 洧녷洧녶洧녷洧녹洧녳洧녩洧노洧녰洧녶洧녵 洧녻洧녰洧노h 洧녴洧뉧롐뀛롐 3.23 洧녫洧녴 洧녩洧녵洧녬 洧녡.洧냥. 2.31 洧녫洧녴 ? 洧녢洧녩洧녲洧 1 % 洧.洧녝.洧녡.\n"
     ]
    }
   ],
   "source": [
    "print('洧냢 洧멇롐뀛롐뛿롐뢣롐뙗롐 洧녶洧녭 900 洧녰洧노洧뉧롐뛿롐 洧녰洧 洧녭洧녶洧녹洧녵洧녬 洧노洧녶 h洧녩洧녺洧 洧녩 洧녴洧뉧롐뀛롐 洧녶洧녭 3.47 洧녫洧녴. 洧냤洧녩洧녵 洧녰洧노 洧녪洧 洧洧뉧롐뀛롐멇롐럻롐洧녩洧녪洧녳洧녽 洧洧뉧롐덣롐뀛롐洧녬洧뉧롐 洧녩洧 洧녩 洧멇롐뒳롐뛿롐뢣롐뙗롐 洧멇롐뀛롐뛿롐뢣롐뙗롐 洧녭洧洧녶洧녴 洧녩 洧녷洧녶洧녷洧녹洧녳洧녩洧노洧녰洧녶洧녵 洧녻洧녰洧노h 洧녴洧뉧롐뀛롐 3.23 洧녫洧녴 洧녩洧녵洧녬 洧녡.洧냥. 2.31 洧녫洧녴 ? 洧녢洧녩洧녲洧 1 % 洧.洧녝.洧녡.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '洧멇롐뒳롐뛿롐뢣롐뙗롐'\n",
    "b = 'simple'\n",
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 0-5: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m normal_text \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode-escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m normal_text \u001b[38;5;241m==\u001b[39m b\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 0-5: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "normal_text = a.encode('ascii').decode('unicode-escape')\n",
    "normal_text == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean breaking strength of the cables supplied by a manufacturer is 1800 with a S. D. of 100. By a new technique in the manufacturing process, it is claimedthatthebreakingstrengthofthecablehasincreased. Totestthis claim, a sample of 50 cables is tested and it is found that the mean breaking strengthis1850.Canwesupporttheclaimat1%L.O.S. ?\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Your styled text\n",
    "styled_text = '洧녢h洧 洧녴洧뉧롐뀛롐 洧녪洧洧뉧롐뀛롐떯롐뒳롐洧녮 洧멇롐뫯롐洧뉧롐洧녮洧노h 洧녶洧녭 洧노h洧 洧녫洧녩洧녪洧녳洧뉧롐 洧멇롐뮗롐뢣롐뢣롐뙗롐뒳롐뉧롐 洧녪洧녽 洧녩 洧녴洧녩洧녵洧녹洧녭洧녩洧녫洧노洧녹洧洧뉧롐 洧녰洧 1800 洧녻洧녰洧노h 洧녩 洧녡. 洧냥. 洧녶洧녭 100. 洧냣洧녽 洧녩 洧녵洧뉧롐 洧노洧뉧롐낟洧녵洧녰洧륋롐뮗롐 洧녰洧녵 洧노h洧 洧녴洧녩洧녵洧녹洧녭洧녩洧녫洧노洧녹洧洧녰洧녵洧녮 洧녷洧洧녶洧녫洧뉧롐멇롐, 洧녰洧노 洧녰洧 洧녫洧녳洧녩洧녰洧녴洧뉧롐놿롐멷洧녩洧노洧노h洧뉧롐洧洧뉧롐뀛롐떯롐뒳롐洧녮洧멇롐뫯롐洧뉧롐洧녮洧노h洧녶洧녭洧노h洧뉧롐넗롐뀛롐洧녳洧뇯洧녩洧멇롐뒳롐洧녫洧洧뉧롐뀛롐멇롐뉧롐. 洧녢洧녶洧노洧뉧롐멇롐뫯롐멷洧녰洧 洧녫洧녳洧녩洧녰洧녴, 洧녩 洧멇롐뀛롐뛿롐뢣롐뙗롐 洧녶洧녭 50 洧녫洧녩洧녪洧녳洧뉧롐 洧녰洧 洧노洧뉧롐멇롐뫯롐뉧롐 洧녩洧녵洧녬 洧녰洧노 洧녰洧 洧녭洧녶洧녹洧녵洧녬 洧노h洧녩洧노 洧노h洧 洧녴洧뉧롐뀛롐 洧녪洧洧뉧롐뀛롐떯롐뒳롐洧녮 洧멇롐뫯롐洧뉧롐洧녮洧노h洧녰洧1850.洧냤洧녩洧녵洧녻洧뉧롐멇롐뮗롐뢣롐뢣롐럻롐洧노洧노h洧뉧롐넗롐뙗롐뀛롐뒳롐뛿롐뀛롐1%洧.洧녝.洧녡. ?'\n",
    "\n",
    "# Normalize the text to remove the styling\n",
    "normalized_text = unicodedata.normalize('NFKC', styled_text)\n",
    "\n",
    "print(normalized_text)  # Output: sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Installing SpeechBrain via pip\n",
    "BRANCH = 'develop'\n",
    "!python -m pip install git+https://github.com/speechbrain/speechbrain.git@$BRANCH\n",
    "\n",
    "# Clone SpeechBrain repository\n",
    "!git clone https://github.com/speechbrain/speechbrain/\n",
    "%cd /content/speechbrain/templates/speech_recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvilshah/tensorflow-test/env/lib/python3.8/site-packages/transformers/configuration_utils.py:379: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2Model: ['project_q.weight', 'quantizer.weight_proj.weight', 'quantizer.codevectors', 'project_q.bias', 'project_hid.bias', 'project_hid.weight', 'quantizer.weight_proj.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "speechbrain.lobes.models.huggingface_transformers.huggingface - Wav2Vec2Model is frozen.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from speechbrain.inference.interfaces import foreign_class\n",
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "out_prob, score, index, text_lab = classifier.classify_file(\"audio_segments/segment_1_20240319094710.wav\")\n",
    "type(text_lab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
